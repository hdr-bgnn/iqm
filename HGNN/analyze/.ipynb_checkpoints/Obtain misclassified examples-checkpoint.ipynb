{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from HGNN.train.configParser import ConfigParser\n",
    "from HGNN.train import CNN, dataLoader\n",
    "\n",
    "experimetnsFileName = \"experiments.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data/\"\n",
    "experimentName=\"BestModelForJeremy\"\n",
    "trial_hash=\"5ca924957d74082b43727d9b435b0ffc4211c656339b57101de62fe8\"\n",
    "\n",
    "cuda=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 6\n"
     ]
    }
   ],
   "source": [
    "# set cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda)\n",
    "    print(\"using cuda\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimentName': 'BestModelForJeremy', 'modelName': 'models/5ca924957d74082b43727d9b435b0ffc4211c656339b57101de62fe8', 'datasetName': 'datasplits/0391575d99c916c8dcef3c314e8a46d4d5d62729da40b220d2dd8266', 'experimentHash': 'b00f2ddb12d0105857df5ac7616ba69f3e41bf02de9a23539673a4b3', 'image_path': 'INHS_cropped', 'suffix': 52, 'training_count': 0.64, 'validation_count': 0.16, 'batchSize': 32, 'n_epochs': 5000, 'learning_rate': 0.01, 'numOfTrials': 5, 'patience': 50, 'fc_width': 200, 'fc_layers': 1, 'modelType': 'BB', 'lambda': 0.6, 'unsupervisedOnTest': False, 'tl_model': 'ResNet18', 'augmented': False, 'trialHash': '5ca924957d74082b43727d9b435b0ffc4211c656339b57101de62fe8'}\n",
      "Creating dataset...\n",
      "Creating dataset... Done.\n",
      "Loading saved indices...\n",
      "file /home/elhamod/HGNN/experiments/BestModelForJeremy/datasplits/9258154089fd66cb9afba0b868cb85ab74760f54977fb89f64977042/trainingIndex.csv read\n",
      "file /home/elhamod/HGNN/experiments/BestModelForJeremy/datasplits/9258154089fd66cb9afba0b868cb85ab74760f54977fb89f64977042/valIndex.csv read\n",
      "file /home/elhamod/HGNN/experiments/BestModelForJeremy/datasplits/9258154089fd66cb9afba0b868cb85ab74760f54977fb89f64977042/testIndex.csv read\n",
      "Creating loaders...\n",
      "Creating loaders... Done.\n"
     ]
    }
   ],
   "source": [
    "# Get experiment parameters\n",
    "experimentsFileNameAndPath = os.path.join(experimentsPath, experimetnsFileName)\n",
    "if os.path.exists(experimentsFileNameAndPath):\n",
    "    experiments_df = pd.read_csv(experimentsFileNameAndPath)\n",
    "else:\n",
    "    raise Exception(\"Experiment not \" + trial_hash + \" found!\")\n",
    "experimentRecord = experiments_df[experiments_df[\"trialHash\"] == trial_hash]\n",
    "experiment_params = experimentRecord.to_dict('records')[0]\n",
    "print(experiment_params)\n",
    "\n",
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "datasetManager = dataLoader.datasetManager(experimentPathAndName)\n",
    "datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "dataset = datasetManager.getDataset()\n",
    "train_loader, validation_loader, test_loader = datasetManager.getLoaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = {\n",
    "    \"fine\": len(dataset.csv_processor.getFineList()),\n",
    "    \"coarse\" : len(dataset.csv_processor.getCoarseList())\n",
    "}\n",
    "model = CNN.create_model(architecture, experiment_params)\n",
    "\n",
    "# get the model and the parameters\n",
    "modelName = experimentRecord.iloc[0][\"modelName\"]\n",
    "trialName = os.path.join(experimentPathAndName, modelName)\n",
    "_ = CNN.loadModel(model, trialName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort through predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_misclassified = pd.DataFrame(columns=['file name', 'true label', 'probability of true label', 'predicted label'])\n",
    "df_correctlyclassified = pd.DataFrame(columns=['file name', 'true label', 'probability of true label', 'predicted label'])\n",
    "\n",
    "# get probability of correct prediction and true label\n",
    "predProblist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "_, predlist = torch.max(predProblist, 1)\n",
    "lbllist = lbllist.reshape(lbllist.shape[0], -1)\n",
    "predProblist = predProblist.gather(1, lbllist)\n",
    "predProblist = predProblist.reshape(1, -1)\n",
    "predProblist = predProblist[0]\n",
    "\n",
    "# sort through\n",
    "predProblist, indices = torch.sort(predProblist)\n",
    "predlist = predlist[indices]\n",
    "lbllist = lbllist[indices]\n",
    "\n",
    "for i, lbl in enumerate(lbllist):\n",
    "    prd = predlist[i]\n",
    "    prdProb = predProblist[i]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        lbl = lbl.cpu()\n",
    "        prd = prd.cpu()\n",
    "        prdProb = prdProb.cpu()\n",
    "\n",
    "    s = dataset[i]\n",
    "    row = {'file name' : s['fileName'] , \n",
    "           'true label' : int(lbl.numpy()), \n",
    "           'probability of true label': float(prdProb.numpy()),\n",
    "           'predicted label' : int(prd.numpy())}\n",
    "    \n",
    "    if(lbl != prd):\n",
    "        df_misclassified = df_misclassified.append(row, ignore_index=True)\n",
    "    else:\n",
    "        df_correctlyclassified = df_correctlyclassified.append(row, ignore_index=True)\n",
    "        \n",
    "df_misclassified = df_misclassified.sort_values(by=[ 'true label', 'probability of true label'])\n",
    "df_correctlyclassified = df_correctlyclassified.sort_values(by=['true label', 'probability of true label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display and save mispredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                file name true label  probability of true label  \\\n",
      "8     INHS_FISH_86189.jpg          1                   0.000081   \n",
      "87   INHS_FISH_109160.jpg          1                   0.026495   \n",
      "12    INHS_FISH_26594.jpg          2                   0.000165   \n",
      "23    INHS_FISH_53927.jpg          2                   0.000701   \n",
      "103   INHS_FISH_99597.jpg          2                   0.155637   \n",
      "..                    ...        ...                        ...   \n",
      "45    INHS_FISH_81157.jpg         47                   0.012202   \n",
      "106   INHS_FISH_17458.jpg         48                   0.251948   \n",
      "28    INHS_FISH_42353.jpg         50                   0.001204   \n",
      "89   INHS_FISH_106542.jpg         50                   0.029034   \n",
      "3    INHS_FISH_012567.jpg         51                   0.000023   \n",
      "\n",
      "    predicted label  \n",
      "8                 9  \n",
      "87                9  \n",
      "12               48  \n",
      "23               41  \n",
      "103              39  \n",
      "..              ...  \n",
      "45               49  \n",
      "106              50  \n",
      "28                8  \n",
      "89                8  \n",
      "3                18  \n",
      "\n",
      "[111 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_misclassified)\n",
    "df_misclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'misclassified examples.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and display correctly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filename of correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                file name true label  probability of true label  \\\n",
      "18    INHS_FISH_20471.jpg          0                   0.695103   \n",
      "51   INHS_FISH_104363.jpg          0                   0.967019   \n",
      "122   INHS_FISH_44752.jpg          0                   0.998992   \n",
      "184  INHS_FISH_101493.jpg          0                   0.999783   \n",
      "202   INHS_FISH_28499.jpg          0                   0.999858   \n",
      "..                    ...        ...                        ...   \n",
      "110   INHS_FISH_90518.jpg         51                   0.998729   \n",
      "152  INHS_FISH_106523.jpg         51                   0.999484   \n",
      "215   INHS_FISH_62499.jpg         51                   0.999898   \n",
      "304    INHS_FISH_4325.jpg         51                   0.999983   \n",
      "385   INHS_FISH_97537.jpg         51                   0.999999   \n",
      "\n",
      "    predicted label  \n",
      "18                0  \n",
      "51                0  \n",
      "122               0  \n",
      "184               0  \n",
      "202               0  \n",
      "..              ...  \n",
      "110              51  \n",
      "152              51  \n",
      "215              51  \n",
      "304              51  \n",
      "385              51  \n",
      "\n",
      "[409 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_correctlyclassified)\n",
    "df_correctlyclassified.to_csv(os.path.join(experimentPathAndName, modelName, 'correctly classified examples.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
