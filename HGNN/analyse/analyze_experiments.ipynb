{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from myhelpers import config_plots, TrialStatistics\n",
    "from HGNN.train import CNN, dataLoader\n",
    "from HGNN.train.configParser import ConfigParser, getModelName, getDatasetName\n",
    "config_plots.global_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentsPath=\"/home/elhamod/HGNN/experiments/\"\n",
    "dataPath=\"/data/BGNN_data\"\n",
    "experimentName=\"BestModelForJeremy\"\n",
    "\n",
    "cuda=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 0\n"
     ]
    }
   ],
   "source": [
    "# set cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(cuda)\n",
    "    print(\"using cuda\", cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = ConfigParser(experimentsPath, dataPath, experimentName)\n",
    "\n",
    "experimentPathAndName = os.path.join(experimentsPath, experimentName)\n",
    "\n",
    "# instantiate trial stat object\n",
    "results_dir = os.path.join(experimentPathAndName, \"results\")\n",
    "ts = TrialStatistics.TrialStatistics(results_dir)\n",
    "ts_coarse = TrialStatistics.TrialStatistics(results_dir, \"coarse\")\n",
    "\n",
    "datasetManager = dataLoader.datasetManager(experimentPathAndName)\n",
    "\n",
    "paramsIterator = config_parser.getExperiments()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show and save trial statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f9b8e5da0e441f89c2ec2356b1fd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='experiment', max=3.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images:  65%|██████▍   | 1685/2600 [02:22<01:25, 10.72it/s, fileName=INHS_FISH_18909.jpg]  "
     ]
    }
   ],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for experiment_params in config_parser.getExperiments():\n",
    "        \n",
    "        datasetManager.updateParams(config_parser.fixPaths(experiment_params))\n",
    "        dataset = datasetManager.getDataset()\n",
    "        \n",
    "        # For analyzing experiments, we don't care about augmentation\n",
    "        dataset.toggle_image_loading(augmentation=False, normalization=dataset.normalization_enabled)\n",
    "        \n",
    "        train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "        fineList = dataset.csv_processor.getFineList()\n",
    "        coarseList = dataset.csv_processor.getCoarseList()\n",
    "        numberOffine = len(fineList)\n",
    "        numberOfcoarse = len(coarseList)\n",
    "        architecture = {\n",
    "            \"fine\": numberOffine,\n",
    "            \"coarse\" : numberOfcoarse\n",
    "        }\n",
    "        \n",
    "        # Loop through n trials\n",
    "        for i in trange(experiment_params[\"numOfTrials\"], desc=\"trial\"):\n",
    "            modelName = getModelName(experiment_params, i)\n",
    "            trialName = os.path.join(experimentPathAndName, modelName)\n",
    "            \n",
    "            # Train/Load model\n",
    "            print(experiment_params)\n",
    "            model = CNN.create_model(architecture, experiment_params)\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                df, epochs, time_elapsed = CNN.loadModel(model, trialName)\n",
    "                \n",
    "                # Update trial outcomes for statistics\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params)\n",
    "                ts.addTrialPredictions(experiment_params, predlist, lbllist, numberOffine)\n",
    "                micro_f1 = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "                predlist, lbllist = CNN.getLoaderPredictionProbabilities(test_loader, model, experiment_params)\n",
    "                topk = CNN.top_k_acc(predlist, lbllist, topk=(3,5))\n",
    "\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params, 'coarse')\n",
    "                ts_coarse.addTrialPredictions(experiment_params, predlist, lbllist, numberOfcoarse)\n",
    "                micro_f1_coarse = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(validation_loader, model, experiment_params)\n",
    "                macro_f1_val = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "                score = {'loss': CNN.getCrossEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                         'average correct guess prob': CNN.getAvgProbCorrectGuessFromLoader(test_loader, model, experiment_params),\n",
    "                         'macro f1 test fine': micro_f1,\n",
    "                         'macro f1 test coarse': micro_f1_coarse,\n",
    "                         'macro f1 validation fine': macro_f1_val,\n",
    "                         'time': time_elapsed,\n",
    "                         'epochs': epochs,\n",
    "                         'top-3': topk[0].cpu().numpy(),\n",
    "                         'top-5': topk[1].cpu().numpy(),\n",
    "                        }\n",
    "\n",
    "                ts.addTrial(experiment_params,\n",
    "                    score, i)\n",
    "            else:\n",
    "                print(\"Model {0} not found!\".format(trialName))\n",
    "        \n",
    "        bar.update()\n",
    "        \n",
    "# Save experiment results\n",
    "ts.saveStatistics()\n",
    "ts.saveStatistics(False)\n",
    "ts.showStatistics()\n",
    "ts.showStatistics(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show and save confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tqdm(total=number_of_experiments, desc=\"experiment\") as bar:\n",
    "    for experiment_params in config_parser.getExperiments():\n",
    "        print(experiment_params)\n",
    "        \n",
    "        ts.printTrialConfusionMatrix(experiment_params, fineList, printOutput=True)\n",
    "        ts_coarse.printTrialConfusionMatrix(experiment_params,  coarseList, printOutput=True)\n",
    "        \n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
